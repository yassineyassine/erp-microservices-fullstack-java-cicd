image: jhipster/jhipster:v8.10.0

variables:
  PROJECT_NAME: store
  IMAGE_NAME: "store"

cache:
  key: '$CI_COMMIT_REF_NAME'
  paths:
    - .maven/



stages:
  - check
  - test
  - analyze
  - build
  - deploy-nexus
  - deploy-store




nohttp:
  stage: check
  tags:
    - docker
  script:
    - git remote set-url origin http://172.21.234.103:8929/root/store.git
    - git config --global --add safe.directory /builds/root/store
    - bash ./mvnw -ntp checkstyle:check -Dmaven.repo.local=$MAVEN_USER_HOME
  when: manual


maven-test:
  services:
    - docker:dind
  variables:
    DOCKER_HOST: 'tcp://docker:2375'
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ''
  stage: test
  script:
    - bash ./mvnw -ntp verify -P-store -Dmaven.repo.local=$MAVEN_USER_HOME
  artifacts:
    reports:
      junit:
        - target/surefire-reports/TEST-*.xml
        - target/failsafe-reports/TEST-*.xml
    paths:
      - target/surefire-reports
      - target/failsafe-reports
      - target/site
    expire_in: 1 day
  when: manual

sonar-analyze:
  stage: analyze
  image: maven:3.9.4-eclipse-temurin-21
  script:
    - mvn org.jacoco:jacoco-maven-plugin:prepare-agent initialize sonar:sonar -Dsonar.host.url=$SONAR_HOST_URL -Dsonar.login=$SONAR_TOKEN -Dsonar.gitlab.project_id=$CI_PROJECT_PATH -Dsonar.gitlab.ref_name=$CI_COMMIT_REF_NAME -Dsonar.gitlab.commit_sha=$CI_COMMIT_SHA -Dsonar.gitlab.failure_notification_mode=exit-code -Dmaven.repo.local=${MAVEN_USER_HOME}

  when: manual
  allow_failure: true


# Ã‰tape 1 : Build Java
build-app:
  stage: build
  image: maven:3.9-eclipse-temurin-17
  variables:
    MAVEN_USER_HOME: "$CI_PROJECT_DIR/.maven"
  script:
    - bash ./mvnw -ntp clean package -Pprod -DskipTests -Dmaven.repo.local=$MAVEN_USER_HOME
    - export PROJECT_VERSION=$(./mvnw -ntp help:evaluate -Dexpression=project.version -q -DforceStdout)
    - echo $PROJECT_VERSION > project-version.txt
  artifacts:
    paths:
      - target/
      - project-version.txt
      - Dockerfile
  when: manual
      
deploy-nexus:
  stage: deploy-nexus
  image:
    name: gcr.io/kaniko-project/executor:v1.23.2-debug
    entrypoint: [""]

  variables:
    DOCKER_CONFIG: "/kaniko/.docker/"
    IMAGE_NAME: "store"
    NEXUS_HOST_URL: "$NEXUS_HOST_URL"

  script:
    - mkdir -p /kaniko/.docker
    - echo "{\"auths\":{\"${NEXUS_HOST_URL}\":{\"username\":\"admin\",\"password\":\"admin\"}},\"insecure-registries\":[\"${NEXUS_HOST_URL}\"]}" > /kaniko/.docker/config.json
    - cat /kaniko/.docker/config.json
    - /kaniko/executor --context $CI_PROJECT_DIR --dockerfile $CI_PROJECT_DIR/Dockerfile --destination ${NEXUS_HOST_URL}/${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} --destination ${NEXUS_HOST_URL}/${IMAGE_NAME}:latest --insecure --skip-tls-verify
  when: manual  







deploy-store:
  stage: deploy-store
  image: alpine/helm:3.12.0
  when: manual
  only:
    - dev
  variables:
    HELM_HOME: /root/.helm
  before_script:
    - apk add --no-cache git curl bash kubectl
    - git clone https://oauth2:$CI_JOB_TOKEN@172.21.234.103:8929/groupedev/helm.git
    - echo "$K8S_TOKEN" > token.txt
    - kubectl config set-cluster k3s --server=$K8S_API_SERVER --insecure-skip-tls-verify=true
    - kubectl config set-credentials gitlab --token=$(cat token.txt)
    - kubectl config set-context default --cluster=k3s --user=gitlab --namespace=$K8S_NAMESPACE
    - kubectl config use-context default
    - helm dependency update ./helm/charts/store || true
  script:
    - helm upgrade --install store-service ./helm/charts/store \
      --namespace $K8S_NAMESPACE \
      --atomic \
      --set image.repository=$NEXUS_HOST_URL \
      --set image.tag=store
